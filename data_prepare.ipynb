{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e88e0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from imblearn import over_sampling\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import  MultiLabelBinarizer,LabelBinarizer\n",
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b8fb5ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Collecting emoji\n",
      "  Downloading emoji-1.6.1.tar.gz (170 kB)\n",
      "     |████████████████████████████████| 170 kB 6.4 MB/s            \n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: emoji\n",
      "  Building wheel for emoji (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for emoji: filename=emoji-1.6.1-py3-none-any.whl size=169314 sha256=d8299afd6e9a78c7081371b2bd10ad45e0fdacd509edd8d0b415991e94d1f703\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/ea/5f/d3/03d313ddb3c2a1a427bb4690f1621eea60fe6f2a30cc95940f\n",
      "Successfully built emoji\n",
      "Installing collected packages: emoji\n",
      "Successfully installed emoji-1.6.1\n"
     ]
    }
   ],
   "source": [
    "!pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "acd6681b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def emoji_idx(s):\n",
    "    res=[]\n",
    "    try:\n",
    "        co = re.compile(u'['u'\\U0001F300-\\U0001F64F' u'\\U0001F680-\\U0001F6FF'u'\\u2600-\\u2B55]+')\n",
    "    except re.error:\n",
    "        co = re.compile(u'('u'\\ud83c[\\udf00-\\udfff]|'u'\\ud83d[\\udc00-\\ude4f\\ude80-\\udeff]|'u'[\\u2600-\\u2B55])+')\n",
    "    it = co.finditer(s)\n",
    "    for i in it:\n",
    "        res.append(i.span())\n",
    "    return res\n",
    "\n",
    "def correct_idx(s,lab):\n",
    "    emj=emoji_idx(s)   \n",
    "    if len(emj)==0 or lab=='[]':\n",
    "        return lab\n",
    "    lab=eval(lab)\n",
    "    # print(lab)\n",
    "    for i in range(len(lab)):\n",
    "        lab[i]=list(lab[i])\n",
    "        lab[i][4]=list(lab[i][4])\n",
    "        lab[i][5]=list(lab[i][5])\n",
    "        for j in range(len(emj)):\n",
    "            # print(1)\n",
    "            # print(s)\n",
    "            # print(emj)\n",
    "            # break\n",
    "            if emj[j][0]<=lab[i][4][0]:\n",
    "                lab[i][4][0]-=1\n",
    "                lab[i][4][1]-=1\n",
    "            if emj[j][0]<=lab[i][5][0]:\n",
    "                lab[i][5][0]-=1\n",
    "                lab[i][5][1]-=1\n",
    "        lab[i][4]=(lab[i][4][0],lab[i][4][1])\n",
    "        lab[i][5]=(lab[i][5][0],lab[i][5][1])\n",
    "        lab[i]=(lab[i][0], lab[i][1],lab[i][2],lab[i][3],lab[i][4],lab[i][5])\n",
    "    lab=str(lab)\n",
    "    return lab\n",
    "def clean(path):\n",
    "    df=pd.read_csv(path)\n",
    "    false=[]\n",
    "    false_idx=[]\n",
    "    for i in range(len(df)):\n",
    "        lab=eval(df['aspect_opinion_list'][i])\n",
    "#     print(lab)\n",
    "#     print(lab[4][0])\n",
    "        if df['aspect_opinion_list'][i]=='[]':\n",
    "            continue\n",
    "        for j in range(len(lab)):\n",
    "            if  lab[j][0]!=df['reviews'][i][lab[j][4][0]:lab[j][4][1]] or lab[j][2]!=df['reviews'][i][lab[j][5][0]:lab[j][5][1]]:\n",
    "                false.append(df['reviews'][i])\n",
    "                false_idx.append(i)\n",
    "                break   \n",
    "    return false_idx                                                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "31c8f426",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments=['negative','none','positive']\n",
    "\n",
    "def pick_cn(content):\n",
    "    content = str(content)\n",
    "    REG_CN =\"[\\u4e00-\\u9fa5]\";#包含中文英文数字\n",
    "    for i in content:\n",
    "        if re.match(REG_CN,i) != 'none':\n",
    "            return ''.join(re.findall(REG_CN,content))\n",
    "        else:\n",
    "            return 'none'\n",
    "def replace_emoji(content):\n",
    "    data = content.map(lambda x: emoji.demojize(x))\n",
    "    res = re.sub('\\:.*?\\:','xx',data)\n",
    "    return res\n",
    "\n",
    "def del_blank(content):\n",
    "    separators=[' ']\n",
    "    for separator in separators:\n",
    "        content=content.replace(separator, '')\n",
    "    return content\n",
    "\n",
    "def write_txt(df,path='data/ctrip/train_sample_emoji.txt'):\n",
    "    with open(path,'a')as f:\n",
    "        for i in range(df.shape[0]):\n",
    "            f.write(list(df[i])[0])\n",
    "            f.write('\\n')\n",
    "def write_txt2(df,false,path='data/ctrip/total1119_clean.txt'):\n",
    "    with open(path,'a')as f:\n",
    "        for i in range(len(df)):\n",
    "            if len(df.loc[i,'reviews'])>600 or i in false:\n",
    "                continue\n",
    "            f.write(\"{} ####{}\".format(df.loc[i,'reviews'],df.loc[i,'aspect_opinion_list']))\n",
    "            f.write('\\n')\n",
    "def read_txt(root):\n",
    "    res=[]\n",
    "    with open(root, \"r\") as f:\n",
    "        for line in f.readlines():\n",
    "            line = line.strip('\\n')  #去掉列表中每一个元素的换行符\n",
    "            res.append(line)\n",
    "    return res\n",
    "def filter_emoji(desstr,restr=''):\n",
    "    #过滤表情\n",
    "    try:\n",
    "        co = re.compile(u'[\\U00010000-\\U0010ffff]')\n",
    "    except re.error:\n",
    "        co = re.compile(u'[\\uD800-\\uDBFF][\\uDC00-\\uDFFF]')\n",
    "    return co.sub(restr, desstr)\n",
    "def write_train_test(train_path,test_path,root='data/ctrip/total1109.txt'):\n",
    "    data=read_txt(root)\n",
    "    x_train,x_test=train_test_split(data,test_size=0.2, random_state=42)\n",
    "    with open(train_path,'a')as f1:\n",
    "        for i in range(len(x_train)):\n",
    "            f1.write(x_train[i])\n",
    "            f1.write('\\n')\n",
    "    with open(test_path,'a')as f2:\n",
    "        for i in range(len(x_test)):\n",
    "            f2.write(x_test[i])\n",
    "            f2.write('\\n')\n",
    "            \n",
    "def del_idx(content):\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c40a1206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df=pd.read_csv('data/ctrip/data1119.csv')\n",
    "# df['aspect_opinion_list']=df.apply(lambda x:correct_idx(x.reviews,x.aspect_opinion_list),axis=1)\n",
    "# df.to_csv('data/ctrip/1119clean.csv',index=False)\n",
    "# false=clean('data/ctrip/1119clean.csv')\n",
    "write_txt2(df,false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5aaa6126",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_train_test(train_path='data/ctrip/data_total_1119_clean_train.txt',test_path='data/ctrip/data_total_1119_clean_test.txt',root='data/ctrip/total1119_clean.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "93929b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17593\n",
      "4399\n",
      "21992\n"
     ]
    }
   ],
   "source": [
    "a=read_txt('data/ctrip/data_total_1119_clean_train.txt')\n",
    "print(len(a))\n",
    "a=read_txt('data/ctrip/data_total_1119_clean_test.txt')\n",
    "print(len(a))\n",
    "a=read_txt('data/ctrip/total1119_clean.txt')\n",
    "print(len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "11cb35b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=np.load('labels.npy',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "426bbb87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Nov 29 08:00:21 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.142.00   Driver Version: 450.142.00   CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:00:1E.0 Off |                    0 |\n",
      "| N/A   73C    P0   256W / 300W |  12283MiB / 16160MiB |     95%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A     10195      C   python                          12281MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec7f2b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filesystem      Size  Used Avail Use% Mounted on\n",
      "devtmpfs         30G     0   30G   0% /dev\n",
      "tmpfs            30G  4.0K   30G   1% /dev/shm\n",
      "tmpfs            30G  644K   30G   1% /run\n",
      "tmpfs            30G     0   30G   0% /sys/fs/cgroup\n",
      "/dev/xvda1      130G  115G   16G  88% /\n",
      "/dev/xvdf       493G  199G  269G  43% /home/ec2-user/SageMaker\n",
      "tmpfs           6.0G     0  6.0G   0% /run/user/1002\n",
      "tmpfs           6.0G     0  6.0G   0% /run/user/1000\n",
      "tmpfs           6.0G     0  6.0G   0% /run/user/1001\n"
     ]
    }
   ],
   "source": [
    "!df -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f935c18a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "善财洞和梵音洞\n"
     ]
    }
   ],
   "source": [
    "a='客栈到码头非常近。码头下船以后出门左边，转一个湾就到，到普济寺也很方便步行几百米，装修比较有风格，住的二楼房间不错，老板很热情，旁边吃饭也很方便，出门就是好几个饭店，还有小卖部。客栈卫生也不错，房间安静，下次过去还住这里。这次是我一个人去的，定了一个双人标间。房间比较紧凑，但是又很有风格。如果有时间真的可以在这里小住一段时间。喜欢做民宿的朋友，强烈给大家推荐普陀山普陀小院客栈。对了，顺便给大家说一下。线路一，客栈出门，到马路边上，往右走，就是去南海观音。也可以到码头坐大巴车，五块钱到南海观音停车场。然后可以从南海观音出来以后，到紫竹林和不肯去观音寺。紫竹林出来以后也可以选择步行到普济寺，也可以做大巴车，五块钱到普济寺。线路二，往左走就是去普济寺，也可以坐大巴车，到西山景区，下车往前走200米左右，就是普济寺。普济寺出来以后可以去百子堂。然后可以选择步行或者坐大巴车去南海观音，那还观音出来去紫竹林和不肯去观音寺。然后可以在停车场，坐车去法雨寺，法雨寺出来可以选择，爬山去，慧济寺。慧济寺可以坐索道下山到停车场然后坐车去，善财洞和梵音洞。然后选择做车回码头到客栈。因为客栈离码头很近，所以到什么地方坐车都很方便。以上仅供大家参考'\n",
    "print(a[465:472])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbf3f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sh eval.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b98eb31c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filesystem      Size  Used Avail Use% Mounted on\n",
      "devtmpfs        241G     0  241G   0% /dev\n",
      "tmpfs           241G  964M  240G   1% /dev/shm\n",
      "tmpfs           241G  896K  241G   1% /run\n",
      "tmpfs           241G     0  241G   0% /sys/fs/cgroup\n",
      "/dev/xvda1      120G  109G   12G  91% /\n",
      "/dev/xvdf       493G  116G  352G  25% /home/ec2-user/SageMaker\n",
      "tmpfs            49G     0   49G   0% /run/user/1002\n",
      "tmpfs            49G     0   49G   0% /run/user/1000\n",
      "tmpfs            49G     0   49G   0% /run/user/1001\n"
     ]
    }
   ],
   "source": [
    "!df -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "850670c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, '2', 3, '4']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=(1,2,3,'4')\n",
    "a=list(a)\n",
    "a[1]=str(a[1])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6f69e31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('', '')]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "lab=np.load('./labels2.npy',allow_pickle=True)\n",
    "pre=np.load('./predictions_nofix2.npy',allow_pickle=True)\n",
    "print(lab[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7b2e3aee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['民族特色', '文化主题', '没做出质感', '负', '(3, 6)', '(7, 11)']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a='民族特色, 文化主题, 没做出质感, 负, (3, 6), (7, 11)'\n",
    "a=a.split(', ')\n",
    "b=[a[0],a[1],a[2],a[3],a[4]+', '+a[5],a[6]+', '+a[7]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f366a32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'12 3344 5'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a='12 34 5'\n",
    "a[3:5]\n",
    "a=a[:3]+'3344'+a[5:]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "543da3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_annotated_aste_targets(sents, labels):\n",
    "    senttag2word = {'POS': 'positive', 'NEG': 'negative', 'NEU': 'neutral'}\n",
    "\n",
    "    annotated_targets = []\n",
    "    num_sents = len(sents)\n",
    "    for i in range(num_sents):\n",
    "        tuples = labels[i]\n",
    "        # tup: ([2], [5], 'NEG')\n",
    "        for tup in tuples:\n",
    "            ap, op, sent = tup[0], tup[1], tup[2]\n",
    "            op = [sents[i][j] for j in op]\n",
    "            # multiple OT for one AP\n",
    "            if '[' in sents[i][ap[0]]:\n",
    "                # print(i)\n",
    "                if len(ap) == 1:\n",
    "                    sents[i][ap[0]] = f\"{sents[i][ap[0]][:-1]}, {' '.join(op)}]\"\n",
    "                else:\n",
    "                    sents[i][ap[-1]] = f\"{sents[i][ap[-1]][:-1]}, {' '.join(op)}]\"\n",
    "            else:\n",
    "                annotation = f\"{senttag2word[sent]}|{' '.join(op)}\"\n",
    "                if len(ap) == 1:\n",
    "                    sents[i][ap[0]] = f\"[{sents[i][ap[0]]}|{annotation}]\"\n",
    "                else:\n",
    "                    sents[i][ap[0]] = f\"[{sents[i][ap[0]]}\"\n",
    "                    sents[i][ap[-1]] = f\"{sents[i][ap[-1]]}|{annotation}]\"\n",
    "        annotated_targets.append(sents[i])\n",
    "    return annotated_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9df654d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['[Screen|positive|awesome]', 'is', 'awesome', ',', '[battery', 'life|positive|good]', 'is', 'good', '.']]\n"
     ]
    }
   ],
   "source": [
    "sents, labels=['Screen is awesome , battery life is good .'],[[([0], [2], 'POS'), ([4, 5], [7], 'POS')]]\n",
    "sents[0]=sents[0].split(' ')\n",
    "a=get_annotated_aste_targets(sents, labels)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb226959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180\n"
     ]
    }
   ],
   "source": [
    "a='客栈到码头非常近。码头下船以后出门左边,转一个湾就到,到普济寺也很方便步行几百米,装修比较有风格,住的二楼房间不错,老板很热情,旁边吃饭也很方便,出门就是好几个饭店,还有小卖部。客栈卫生也不错,房间安静,下次过去还住这里。这次是我一个人去的,定了一个双人标间。房间比较紧凑,但是又很有风格。如果有时间真的可以在这里小住一段时间。喜欢做民宿的朋友,强烈给大家推荐'\n",
    "print(len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e84c1c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_line_examples_from_file(data_path):\n",
    "    \"\"\"\n",
    "    Read data from file, each line is: sent####labels\n",
    "    Return List[List[word]], List[Tuple]\n",
    "    \"\"\"\n",
    "    sents, labels, total = [], [], []\n",
    "    with open(data_path, 'r', encoding='UTF-8') as fp:\n",
    "        words, labels, total = [], [], []\n",
    "        for line in fp:\n",
    "            line = line.strip()\n",
    "            if line != '':\n",
    "                total.append(line)\n",
    "                words, tuples = line.split('####')\n",
    "                sents.append(words.split())\n",
    "                # sents.append(words)\n",
    "                labels.append(eval(tuples))\n",
    "    print(f\"Total examples = {len(sents)}\")\n",
    "    return sents, labels, total\n",
    "def cal_rate(labs):\n",
    "    num_dict=dict()\n",
    "    num_dict[' ']=0\n",
    "    num=0\n",
    "    for i in range(len(labs)):\n",
    "        lab=list(set(labs[i]))\n",
    "        num+=len(lab)\n",
    "        if len(lab)==0:\n",
    "            num+=1\n",
    "            num_dict[' ']+=1\n",
    "        for j in range(len(lab)):\n",
    "            if (lab[j][1],lab[j][3]) not in num_dict.keys():\n",
    "                num_dict[(lab[j][1],lab[j][3])]=1\n",
    "            else:\n",
    "                num_dict[(lab[j][1],lab[j][3])]+=1\n",
    "    for key,val in num_dict.items():\n",
    "        num_dict[key]=num_dict[key]/num\n",
    "    return num_dict,num\n",
    "def build_xy(total,lab):\n",
    "    x,y=[],[]\n",
    "    for i in range(len(lab)):\n",
    "        if len(lab[i])==0:\n",
    "            x.append(total[i])\n",
    "            y.append(' ')\n",
    "        for j in range(len(lab[i])):\n",
    "            x.append(total[i])\n",
    "            y.append((lab[i][j][1],lab[i][j][3]))\n",
    "    return (x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d4b994bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total examples = 17757\n"
     ]
    }
   ],
   "source": [
    "sents,lab,total=read_line_examples_from_file('./data/tasd-cn/ctrip/train.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1a69dea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20020, 1)\n"
     ]
    }
   ],
   "source": [
    "dic,num=cal_rate(lab)\n",
    "keys=list(dic.keys())\n",
    "# x,y=build_xy(total,lab)\n",
    "x,labs=build_xy(total,lab)\n",
    "x=np.array(x)\n",
    "x=x.reshape((-1,1))\n",
    "print(x.shape)\n",
    "y=[]\n",
    "for i in labs:\n",
    "    y.append(keys.index(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27968022",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y)\n",
    "# mlb = MultiLabelBinarizer()\n",
    "# y_ = mlb.fit_transform(y)\n",
    "# label_ = mlb.inverse_transform(y_)\n",
    "# print(y_[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ebf2c5b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(613190, 1)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ros = over_sampling.RandomOverSampler(random_state=0)\n",
    "X_resampled, y_resampled = ros.fit_resample(x, y)\n",
    "# plt.scatter(x=X_resampled[:,0],y=X_resampled[:,1],c=y_resampled)\n",
    "# sorted(Counter(y_resampled).items())\n",
    "X_resampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d384e191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"一路上住了很多家酒店和民宿，这家很满意，必须给5分：到达时比较晚了，门口看不出来里面乾坤，但是一进门就感觉到客栈比较宽广了，实木风格，二层结构，房间比较宽敞明亮安静干净整洁，劳累了一天住进来心里感觉很好👍老板很热情，告诉了一个夜观星象的地方😄 ####[('客栈', '面积', '比较宽广', '正', (54, 56), (56, 60)), ('房间', '面积', '比较宽敞', '正', (72, 74), (74, 78))]\""
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(X_resampled[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "488ed3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_txt(X_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "677aaab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "613190\n"
     ]
    }
   ],
   "source": [
    "a=read_txt('data/ctrip/train_sample_emoji.txt')\n",
    "print(len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "702b3471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"一路上住了很多家酒店和民宿，这家很满意，必须给5分：到达时比较晚了，门口看不出来里面乾坤，但是一进门就感觉到客栈比较宽广了，实木风格，二层结构，房间比较宽敞明亮安静干净整洁，劳累了一天住进来心里感觉很好👍老板很热情，告诉了一个夜观星象的地方😄 ####[('客栈', '面积', '比较宽广', '正', (54, 56), (56, 60)), ('房间', '面积', '比较宽敞', '正', (72, 74), (74, 78))]\""
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "de98e989",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.load('./labels.npy',allow_pickle=True)\n",
    "p=np.load('./predictions_nofix.npy',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "31ed6a41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('孩子体验感受', '正')]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2ea15d32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('儿童玩具', '正')]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0c01902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'result': '(小孩早餐, 儿童餐饮, 送了点👍, 正)', 'infer_time': '0:00:00.725859'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from boto3.session import Session\n",
    "import json\n",
    "# df=pd.read_csv('./data/hp/summary/news_summary_cleaned_small_test.csv')\n",
    "# print('原文:',df.loc[0,'text'])\n",
    "# print('真实标签:',df.loc[0,'headlines'])\n",
    "data={\"data\": '早餐一般般，勉勉强强填饱肚子，样式可选性不多，可能是疫情的影响吧。不过酒店的服务不错，五个小孩早餐都送了，点👍。由于酒店历史有点长，所以设施感觉一般般，整体还可以，三钻吧'}\n",
    "session = Session()\n",
    "    \n",
    "runtime = session.client(\"runtime.sagemaker\")\n",
    "response = runtime.invoke_endpoint(\n",
    "    EndpointName='absa',\n",
    "    ContentType=\"application/json\",\n",
    "    Body=json.dumps(data),\n",
    ")\n",
    "\n",
    "result = json.loads(response[\"Body\"].read())\n",
    "print (result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0fe94c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_mxnet_p36",
   "language": "python",
   "name": "conda_amazonei_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
