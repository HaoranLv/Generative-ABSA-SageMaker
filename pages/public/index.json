[{"uri":"/","title":"AWS Datalab-文档摘要","tags":[],"description":"","content":"Author\n JUNYI LIU (AWS GCR Applied Scientist)  概述 本次workshop分为几个部分\n 背景介绍- what is text summary？ 基于Amazon SageMaker的TEXTRANK模型训练动手实验 基于Amazon SageMaker的Huggingface训练一个BART英文摘要模型  模型训练ß 模型部署   基于Amazon SageMaker的MT5模型训练动手实验  本地模型训练 启动模型训练任务 模型部署   基于Amazon SageMaker的CPT模型训练动手实验  模型训练 模型增强训练 模型部署    本次 workshop 前提 本次 workshop 建议在 US-WEST-2 Region 使用。为了演示方便，所以本 workshop 所有的演示都会以US-WEST-2 Region 为例。\n"},{"uri":"/01introduction.html","title":"Introduction","tags":[],"description":"","content":"text summary（文档摘要） 随着互联网产生的文本数据越来越多，文本信息过载问题日益严重，对各类文本进行一个“降 维”处理显得非常必要，文本摘要便是其中一个重要的手段。 文本摘要旨在将文本或文本集合转换为包含关键信息的简短摘要。 文本摘要按照输入类型可分为单文档摘要和多文档摘要。单文档摘要从给定的一个文档中生成摘要，多文档摘要从给定的一组主题相关的文档中生成摘要。 按照输出类型可分为抽取式摘要和生成式摘要。抽取式摘要从源文档中抽取关键句和关键词组成摘要，摘要全部来源于原文。生成式摘要根据原文，允许生成新的词语、短语来组成摘要。 按照有无监督数据可以分为有监督摘要和无监督摘要。 本文主要关注单文档、有监督、抽取式、生成式摘要。\n"},{"uri":"/01introduction/100algorithm.html","title":"1.1 算法概述","tags":[],"description":"","content":"使用场景 根据生成方式可以分为生成式摘要和抽取式摘要。\n 抽取式摘要：找到一个文档中最重要的几个句子并对其进行拼接。 生成式摘要：是一个序列生成问题，通过源文档序列, 生成序列摘要序列  本workshop主要覆盖以下几个算法，对比结果如下\n Pegasus BART  "},{"uri":"/01introduction/200data.html","title":"1.2 数据集","tags":[],"description":"","content":"1.公开数据集 (英文)  XSUM 227k BBC articles CNN/Dailymail，93k articles from the CNN, 220k articles from the Daily Mail NEWSROOM，1.3M article-summary pairs written by authors and editors in the newsrooms of 38 major publications Multi-News，56k pairs of news articles and their human-written summaries from the http://sitenewser.com Gigaword，4M examples extracted from news articles，the task is to generate theheadline from the first sentence arXiv, PubMed，two long documentdatasets of scientific publications from http://arXiv.org (113k) andPubMed (215k). The task is to generate the abstract fromthe paper body. BIGPATENT，1.3 millionU.S. patents along with human summaries under nine patent classification categories WikiHow在线http://WikiHow.com网站上的大量说明数据集。 200k示例中的每一个示例都包含多个指令步骤段落以及一个摘要句子。 任务是从段落中生成串联的摘要句。 Reddit TIFU，120K posts of informal stories from the online discussion forum Reddit AESLC 18k email bodies and their subjects from the Enron corpus BillSum 23k USCongressional bills and human-written reference summaries from the 103rd-115th (1993-2018) sessions of Congress.  2.公开数据集 (中文)  哈工大的新浪微博短文本摘要 LCSTS 教育新闻自动摘要语料chinese_abstractive_corpus NLPCC 2017 task3 Single Document Summarization 娱乐新闻等 “神策杯”2018高校算法大师赛 清华 THUCNews 总数量：830749个样本； 标题：平均字数 19，字数标准差 4，最大字数 48，最小数字 4； 正文：平均字数 892，字数标准差 1012，最大字数 78796，最小数字 31；  "},{"uri":"/01introduction/300metrics.html","title":"1.3 评估指标","tags":[],"description":"","content":"文本生成目前的一大瓶颈是如何客观，准确的评价机器生成文本的质量。自动文档摘要评价方法大致分为两类：\n（1）内部评价方法：提供参考摘要，以参考摘要为基准评价系统摘要的质量。系统摘要与参考摘要越吻合，质量越高。\n（2）外部评价方法：不提供参考摘要，利用文档摘要代替原文档执行某个文档相关的应用。例如：文档检索、文档分类等，能够提高应用性能的摘要被认为是质量好的摘要。\n下面介绍两种比较简单的，经常用到的内部评价方法：\nEdmundson 适于抽取式文本摘要，比较机械文摘(自动文摘系统得到的文摘)与目标文摘(从原文中抽取的句子)的句子重合率的高低对系统摘要进行评价。\n计算公式：\n 重合率p = 匹配句子数/专家文摘句子数*100%  每一个机械文摘的重合率为按三个专家给出的文摘得到的重合率的平均值（其中，pi为相对于第i个专家的重合率，n为专家文摘总数）： ROUGE ROUGE（Recall-Oriented Understudy for Gisting Evaluation）基于摘要中n-gram的共现信息评价摘要，是一种面向n元词召回率的评价方法。 其中，Ref summaries表示标准摘要，count_match(n-gram)表示生成摘要和标准摘要中同时出现n-gram的个数，count(n-gram)表示参考摘要中出现的n-gram个数。\n"},{"uri":"/02pegasus/0501train.html","title":"Pegasus模型训练","tags":[],"description":"","content":"我们现在会用sagemaker进行一个pegasus模型的本地训练，使用ML.P3.2xlarge机型。\n数据准备 首先下载代码\ncd SageMaker git clone https://github.com/HaoranLv/nlp_transformer.git 然后打开文件 hp_main.ipynb，逐行运行。\n首先安装环境\n然后处理数据hp_data.ipynb，切分train/test。 注意这里，为了快速产生结果，我们只要用1000条数据训练，100条测试/验证\ntrain_df.to_csv('./data/hp/summary/news_summary_cleaned_train.csv',index=False) test_df.to_csv('./data/hp/summary/news_summary_cleaned_test.csv',index=False) train_df[:1000].to_csv('./data/hp/summary/news_summary_cleaned_small_train.csv',index=False) test_df[:100].to_csv('./data/hp/summary/news_summary_cleaned_small_test.csv',index=False) 模型训练 接下来我们运行训练，首先下载我们已经训练好的模型\n!mkdir -p models/pretrain/pegasus !mkdir -p models/pretrain/bart !mkdir -p ./models/local_train/pegasus-hp !mkdir -p ./models/local_train/bart-hp !aws s3 cp s3://datalab2021/hupo_nlp/models/pegasus/checkpoint-46314.zip models/pretrain/pegasus !aws s3 cp s3://datalab2021/hupo_nlp/models/bart/checkpoint-46314.zip models/pretrain/bart !unzip models/pretrain/pegasus/checkpoint-46314.zip -d models/pretrain/pegasus \u0026gt; /dev/null 2\u0026gt;\u0026amp;1 !unzip models/pretrain/bart/checkpoint-46314.zip -d models/pretrain/bart \u0026gt; /dev/null 2\u0026gt;\u0026amp;1 然后进行模型训练，这里没有用我们训练好的模型，而是使用huggingface上的公开的pegasus-large作为训练起点，为了演示目的，我们只运行一个epoch，大约需要5min\n!python -u examples/pytorch/summarization/run_summarization.py \\ --model_name_or_path google/pegasus-large \\ --do_train \\ --do_eval \\ --per_device_train_batch_size=2 \\ --per_device_eval_batch_size=1 \\ --save_strategy epoch \\ --evaluation_strategy epoch \\ --overwrite_output_dir \\ --predict_with_generate \\ --train_file './data/hp/summary/news_summary_cleaned_small_train.csv' \\ --validation_file './data/hp/summary/news_summary_cleaned_small_test.csv' \\ --text_column 'text' \\ --summary_column 'headlines' \\ --output_dir='./models/local_train/pegasus-hp' \\ --num_train_epochs=1.0 \\ --eval_steps=500 \\ --save_total_limit=3 \\ --source_prefix \u0026quot;summarize: \u0026quot; \u0026gt; train_pegasus.log 训练完成后，会提示日志信息如下\n train  eval   模型结果文件及相应的日志等信息会自动保存在./models/local_train/pegasus-hp/checkpoint-500\n结果本地测试 我们可以直接用这个产生的模型文件进行本地推理。注意这里的模型文件地址的指定为你刚刚训练产生的。\nimport pandas as pd df=pd.read_csv('./data/hp/summary/news_summary_cleaned_small_test.csv') print('原文:',df.loc[0,'text']) print('真实标签:',df.loc[0,'headlines']) from transformers import pipeline summarizer = pipeline(\u0026quot;summarization\u0026quot;, model=\u0026quot;./models/local_train/pegasus-hp/checkpoint-500\u0026quot;) print('模型预测:',summarizer(df.loc[0,'text'], max_length=50)[0]['summary_text']) 输出如下\n原文: Germany on Wednesday accused Vietnam of kidnapping a former Vietnamese oil executive Trinh Xuan Thanh, who allegedly sought asylum in Berlin, and taking him home to face accusations of corruption. Germany expelled a Vietnamese intelligence officer over the suspected kidnapping and demanded that Vietnam allow Thanh to return to Germany. However, Vietnam said Thanh had returned home by himself. 真实标签: Germany accuses Vietnam of kidnapping asylum seeker 模型预测: Germany accuses Vietnam of kidnapping ex-oil exec, taking him home 到这里，就完成了一个模型的训练过程。\n"},{"uri":"/02pegasus/0502train.html","title":"Pegasus模型增强训练","tags":[],"description":"","content":"在完成本地训练后，接下来我们模拟一个增强训练过程。在我们刚才完成的训练任务中，产生了模型文件./models/local_train/pegasus-hp/checkpoint-500，然后，我们运行\n!python -u examples/pytorch/summarization/run_summarization.py \\ --model_name_or_path models/pretrain/pegasus/checkpoint-46314 \\ --do_train \\ --do_eval \\ --per_device_train_batch_size=2 \\ --per_device_eval_batch_size=1 \\ --save_strategy epoch \\ --evaluation_strategy epoch \\ --overwrite_output_dir \\ --predict_with_generate \\ --train_file './data/hp/summary/news_summary_cleaned_small_train.csv' \\ --validation_file './data/hp/summary/news_summary_cleaned_small_test.csv' \\ --text_column 'text' \\ --summary_column 'headlines' \\ --output_dir='./models/local_train/pegasus-hp' \\ --num_train_epochs=1.0 \\ --eval_steps=500 \\ --save_total_limit=3 \\ --source_prefix \u0026quot;summarize: \u0026quot; \u0026gt; train_pegasus_2.log 我们可以看到，在训练时，日志中有如下的记录loading weights file models/pretrain/pegasus/checkpoint-46314/pytorch_model.bin说明模型是导入了一个之前训练的基础版本，也可以通过训练的loss值以及最终的rouge指标判断出这个结果是增强训练产生的。\n同样的，我们可以利用本地推理进行测试。\n本地测试，效果提升明显\nimport pandas as pd df=pd.read_csv('./data/hp/summary/news_summary_cleaned_small_test.csv') print('原文:',df.loc[0,'text']) print('真实标签:',df.loc[0,'headlines']) from transformers import pipeline summarizer = pipeline(\u0026quot;summarization\u0026quot;, model=\u0026quot;./models/local_train/pegasus-hp/checkpoint-500\u0026quot;) print('模型预测:',summarizer(df.loc[0,'text'], max_length=50)[0]['summary_text']) 输出\n原文: Germany on Wednesday accused Vietnam of kidnapping a former Vietnamese oil executive Trinh Xuan Thanh, who allegedly sought asylum in Berlin, and taking him home to face accusations of corruption. Germany expelled a Vietnamese intelligence officer over the suspected kidnapping and demanded that Vietnam allow Thanh to return to Germany. However, Vietnam said Thanh had returned home by himself. 真实标签: Germany accuses Vietnam of kidnapping asylum seeker 模型预测: Germany accuses Vietnam of kidnapping ex-oil exec, taking him home "},{"uri":"/02pegasus.html","title":"动手实验1: 基于Amazon SageMaker的Pegasus摘要模型训练动手实验","tags":[],"description":"","content":"模型架构 Pegasus是一个标准的Transformer架构，其全称是：利用提取的间隙句进行摘要概括的预训练模型（Pre-training with Extracted Gap-sentences for Abstractive Summarization）。就是设计一种间隙句生成的自监督预训练目标（GSG），来改进生成摘要的微调性能。\nGSG预训目标  Mask掉整个句子 将Mask的句子拼接成摘要 使用上下文补全  Mask策略\n模型表现 Pegasus-large在各个摘要数据集上的结果同之前的SOTA对比：在所有数据集上均得到了SOTA的性能表现。\nreference  paper： https://arxiv.org/abs/1912.08777 source code：https://github.com/google-research/pegasus  @misc{zhang2019pegasus, title={PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization}, author={Jingqing Zhang and Yao Zhao and Mohammad Saleh and Peter J. Liu}, year={2020}, eprint={1912.08777}, archivePrefix={ICML}, primaryClass={cs.CL} }\n"},{"uri":"/02pegasus/0503deploy.html","title":"Pegasus模型部署","tags":[],"description":"","content":"首先打包镜像并推送\n!sh build_and push.sh pegasus-hp 然后部署一个预置的endpoint\n#注意修改：847380964353.dkr.ecr.ap-northeast-1.amazonaws.com/pegasus-hp为自己对应的 %cd endpoint !python create_endpoint.py \\ --endpoint_ecr_image_path \u0026#34;847380964353.dkr.ecr.ap-northeast-1.amazonaws.com/pegasus-hp\u0026#34; \\ --endpoint_name \u0026#39;pegasus\u0026#39; \\ --instance_type \u0026#34;ml.p3.2xlarge\u0026#34; %cd .. 输出\nmodel_name: pegasus endpoint_ecr_image_path: 847380964353.dkr.ecr.ap-northeast-1.amazonaws.com/pegasus-hp \u0026lt;\u0026lt;\u0026lt; Completed model endpoint deployment. pegasus 当状态变为InService即代表部署完成\n在部署结束后，看到SageMaker控制台生成了对应的endpoint,可以使用如下客户端代码测试调用\n%%time from boto3.session import Session import json df=pd.read_csv(\u0026#39;./data/hp/summary/news_summary_cleaned_small_test.csv\u0026#39;) print(\u0026#39;原文:\u0026#39;,df.loc[0,\u0026#39;text\u0026#39;]) print(\u0026#39;真实标签:\u0026#39;,df.loc[0,\u0026#39;headlines\u0026#39;]) data={\u0026#34;data\u0026#34;: df.loc[0,\u0026#39;text\u0026#39;]} session = Session() runtime = session.client(\u0026#34;runtime.sagemaker\u0026#34;) response = runtime.invoke_endpoint( EndpointName=\u0026#39;pegasus\u0026#39;, ContentType=\u0026#34;application/json\u0026#34;, Body=json.dumps(data), ) result = json.loads(response[\u0026#34;Body\u0026#34;].read()) print (result) 结果如下\n{'result': '[SEP] [CLS] Germany accuses Vietnam of kidnapping asylum seeker [SEP]', 'infer_time': '0:00:02.948025'} CPU times: user 169 ms, sys: 30.9 ms, total: 200 ms Wall time: 3.42 s "},{"uri":"/categories.html","title":"Categories","tags":[],"description":"","content":""},{"uri":"/tags.html","title":"Tags","tags":[],"description":"","content":""}]