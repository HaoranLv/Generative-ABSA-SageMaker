[{"uri":"/","title":"AWS Datalab-ç»†ç²’åº¦æƒ…æ„Ÿåˆ†æ","tags":[],"description":"","content":"Author\n JUNYI LIU (AWS GCR Applied Scientist)  æ¦‚è¿° æœ¬æ¬¡workshopåˆ†ä¸ºå‡ ä¸ªéƒ¨åˆ†\n èƒŒæ™¯ä»‹ç»- what is text summaryï¼Ÿ åŸºäºAmazon SageMakerçš„TEXTRANKæ¨¡å‹è®­ç»ƒåŠ¨æ‰‹å®éªŒ åŸºäºAmazon SageMakerçš„Huggingfaceè®­ç»ƒä¸€ä¸ªBARTè‹±æ–‡æ‘˜è¦æ¨¡å‹  æ¨¡å‹è®­ç»ƒÃŸ æ¨¡å‹éƒ¨ç½²   åŸºäºAmazon SageMakerçš„MT5æ¨¡å‹è®­ç»ƒåŠ¨æ‰‹å®éªŒ  æœ¬åœ°æ¨¡å‹è®­ç»ƒ å¯åŠ¨æ¨¡å‹è®­ç»ƒä»»åŠ¡ æ¨¡å‹éƒ¨ç½²   åŸºäºAmazon SageMakerçš„CPTæ¨¡å‹è®­ç»ƒåŠ¨æ‰‹å®éªŒ  æ¨¡å‹è®­ç»ƒ æ¨¡å‹å¢å¼ºè®­ç»ƒ æ¨¡å‹éƒ¨ç½²    æœ¬æ¬¡ workshop å‰æ æœ¬æ¬¡ workshop å»ºè®®åœ¨ US-WEST-2 Region ä½¿ç”¨ã€‚ä¸ºäº†æ¼”ç¤ºæ–¹ä¾¿ï¼Œæ‰€ä»¥æœ¬ workshop æ‰€æœ‰çš„æ¼”ç¤ºéƒ½ä¼šä»¥US-WEST-2 Region ä¸ºä¾‹ã€‚\n"},{"uri":"/01introduction.html","title":"Introduction","tags":[],"description":"","content":"ç»†ç²’åº¦æƒ…æ„Ÿåˆ†æä»»åŠ¡ï¼ˆABSAï¼‰ å¯¹äºä¸€å¥é¤é¦†è¯„è®ºï¼šâ€œWaiters are very friendly and the pasta is simply average.â€ï¼Œæåˆ°äº†ä¸¤ä¸ªè¯„è®ºç›®æ ‡ï¼šâ€œwaiterâ€å’Œâ€œpastaâ€ï¼›ç”¨æ¥è¯„ä»·ä»–ä»¬çš„è¯åˆ†åˆ«æ˜¯ï¼šâ€œfriendlyâ€å’Œâ€œaverageâ€ï¼›è¿™å¥è¯è¯„è®ºçš„åˆ†åˆ«æ˜¯é¤é¦†çš„â€œserviceâ€å’Œâ€œfoodâ€æ–¹é¢ã€‚\nä»ç›®æ ‡è¯†åˆ«è§’åº¦ï¼Œé’ˆå¯¹ aspect term å’Œ opinion termï¼Œå­˜åœ¨æŠ½å–é—®é¢˜ï¼›é’ˆå¯¹ aspect categoryï¼Œå­˜åœ¨åˆ†ç±»é—®é¢˜ï¼ˆå‡è®¾é¢„å®šä¹‰ aspect categoriesï¼‰ã€‚ä»æƒ…æ„Ÿåˆ†æè§’åº¦ï¼Œå¯¹ aspect term å’Œ aspect category å­˜åœ¨æƒ…æ„Ÿåˆ†ç±»é—®é¢˜ã€‚è¿™äº›åŸå­ä»»åŠ¡å¦‚ä¸‹å›¾ä¸­é—´å±‚æ‰€ç¤ºã€‚æ³¨æ„ï¼Œä¸€å¥è¯„è®ºé‡Œå¯èƒ½æ²¡æœ‰æ˜¾ç¤ºæåŠ aspect termï¼Œä½†åŒæ ·å¯ä»¥å­˜åœ¨ aspect categoryï¼Œæ¯”å¦‚â€œI was treated rudely.â€è®²çš„æ˜¯â€œserviceâ€ã€‚\n"},{"uri":"/01introduction/100algorithm.html","title":"1.1 ç®—æ³•æ¦‚è¿°","tags":[],"description":"","content":"ä½¿ç”¨åœºæ™¯ æ ¹æ®ä»»åŠ¡å®šä¹‰æ–¹å¼å¯ä»¥åˆ†ä¸ºç«¯åˆ°ç«¯å¼ABSAå’Œpipelineå¼ABSAã€‚\n pipelineå¼ABSAï¼šé€šè¿‡ä¸åŒçš„æ¨¡å‹ç»„ä»¶åˆ†åˆ«å®ŒæˆAE,APCç­‰ä»»åŠ¡åæ­å»ºæˆä¸€ä¸ªpipelineç»„åˆè¾“å‡ºã€‚ ç«¯åˆ°ç«¯å¼ABSAï¼šé€šè¿‡ä¸€ä¸ªæ¨¡å‹ç›´æ¥å®ŒæˆABSAæ‰€å®šä¹‰çš„å…¨éƒ¨æˆ–è€…å¤šä¸ªä»»åŠ¡ã€‚  pipelineå¼ABSA ç«¯åˆ°ç«¯å¼ABSA ä¸šå†…åšæ³• AE Aspect term extraction with history attention and selective transformation(IJCAI 2019) Double embeddings and cnn-based sequence labeling for aspect extraction(ACL 2018)\nSC Aspect level sentiment classification with deep memory net-work(EMNLP 2016) Relational Graph Attention Network for Aspect-based Sentiment Analysis(ACL 2020)\nOE Coupled multi-layer attentions for co-extraction of aspect and opinion terms(AAAI 2017)\nUnified framework A unified model for opinion target extraction and target sentiment prediction(AAAI 2019) An interactive multi-task learning network for end-to-end aspect-based sentiment analysis (ACL 2019) DOER: dual cross-shared RNN for aspect term-polarity co-extraction (ACL 2019)\nGeneral framework Relation-Aware Collaborative Learning for Unified Aspect-Based Sentiment Analysis(ACL 2020) Towards Generative Aspect-Based Sentiment Analysis(ACL 2021)\n"},{"uri":"/01introduction/200data.html","title":"1.2 æ•°æ®é›†","tags":[],"description":"","content":"1.å…¬å¼€æ•°æ®é›† (è‹±æ–‡)åŠå…¶æ ‡æ³¨æ ·ä¾‹ 2.å…¬å¼€æ•°æ®é›† (ä¸­æ–‡)  åŒ—å¤§ (https://github.com/NLPBLCU/Chinese-Multi-Target-Sentiment-Classification-Dataset/blob/master/our_data.7z) 2Kæ¡æ•°æ®ï¼Œ6Kä¸ªaspect ç¾å›¢ (https://raw.githubusercontent.com/viewlei/fsauor2018/master/src/sentiment_analysis_trainingset_annotations.pdf) åŒ…å«105000æ¡è®­ç»ƒæ ·æœ¬ä»¥åŠ15000æ¡æµ‹è¯•æ ·æœ¬ ï¼Œä¸¤å±‚aspectå…±20ç§aspect, å³ä¼ ç»Ÿçš„å¤šåˆ†ç±»é—®é¢˜  "},{"uri":"/01introduction/300metrics.html","title":"1.3 è¯„ä¼°æŒ‡æ ‡","tags":[],"description":"","content":"ç›®å‰çš„ABSAé‡‡ç”¨ç±»ä¼¼åˆ†ç±»ä»»åŠ¡çš„è¯„ä¼°æŒ‡æ ‡ä½œä¸ºè¯„ä¼° å‡†ç¡®ç‡/ç²¾åº¦/å¬å›ç‡/FPR/F1æŒ‡æ ‡ ä»¥ä¸Šäº”ä¸ªæŒ‡æ ‡éƒ½ç¦»ä¸å¼€ä¸‹åˆ—å®šä¹‰ï¼š\n é¢„æµ‹å€¼ä¸ºæ­£ä¾‹ï¼Œè®°ä¸ºPï¼ˆPositiveï¼‰ é¢„æµ‹å€¼ä¸ºåä¾‹ï¼Œè®°ä¸ºNï¼ˆNegativeï¼‰ é¢„æµ‹å€¼ä¸çœŸå®å€¼ç›¸åŒï¼Œè®°ä¸ºTï¼ˆTrueï¼‰ é¢„æµ‹å€¼ä¸çœŸå®å€¼ç›¸åï¼Œè®°ä¸ºFï¼ˆFalseï¼‰  å‡†ç¡®ç‡ å‡†ç¡®ç‡accuracyæ˜¯æˆ‘ä»¬æœ€å¸¸è§çš„è¯„ä»·æŒ‡æ ‡ï¼Œè¿™ä¸ªå¾ˆå®¹æ˜“ç†è§£ï¼Œå°±æ˜¯è¢«åˆ†å¯¹çš„æ ·æœ¬æ•°é™¤ä»¥æ‰€æœ‰çš„æ ·æœ¬æ•°ï¼Œé€šå¸¸æ¥è¯´ï¼Œæ­£ç¡®ç‡è¶Šé«˜ï¼Œåˆ†ç±»å™¨è¶Šå¥½ï¼Œå¦‚ä¸‹ï¼š\n accuracy = (TP+TN)/(TP+TN+FP+FN)  ä¸Šå…¬å¼ä¸­çš„TP+TNå³ä¸ºæ‰€æœ‰çš„æ­£ç¡®é¢„æµ‹ä¸ºæ­£æ ·æœ¬çš„æ•°æ®ä¸æ­£ç¡®é¢„æµ‹ä¸ºè´Ÿæ ·æœ¬çš„æ•°æ®çš„æ€»å’Œï¼ŒTP+TN+FP+FNå³ä¸ºæ€»æ ·æœ¬çš„ä¸ªæ•°ã€‚\nç²¾åº¦ ç²¾åº¦precisionæ˜¯ä»é¢„æµ‹ç»“æœçš„è§’åº¦æ¥ç»Ÿè®¡çš„ï¼Œæ˜¯è¯´é¢„æµ‹ä¸ºæ­£æ ·æœ¬çš„æ•°æ®ä¸­ï¼Œæœ‰å¤šå°‘ä¸ªæ˜¯çœŸæ­£çš„æ­£æ ·æœ¬ï¼Œå³â€œæ‰¾çš„å¯¹â€çš„æ¯”ä¾‹ï¼Œå¦‚ä¸‹ï¼š\n precision = TP/( TP+FP)  ä¸Šå…¬å¼ä¸­çš„TP+FPå³ä¸ºæ‰€æœ‰çš„é¢„æµ‹ä¸ºæ­£æ ·æœ¬çš„æ•°æ®ï¼ŒTPå³ä¸ºé¢„æµ‹æ­£ç¡®çš„æ­£æ ·æœ¬ä¸ªæ•°ã€‚\nå¬å›ç‡/TPR å¬å›ç‡recallå’ŒTPR(çµæ•åº¦(true positive rate))æ˜¯ä¸€ä¸ªæ¦‚å¿µï¼Œéƒ½æ˜¯ä»çœŸå®çš„æ ·æœ¬é›†æ¥ç»Ÿè®¡çš„ï¼Œæ˜¯è¯´åœ¨æ€»çš„æ­£æ ·æœ¬ä¸­ï¼Œæ¨¡å‹æ‰¾å›äº†å¤šå°‘ä¸ªæ­£æ ·æœ¬ï¼Œå³â€œæ‰¾çš„å…¨â€çš„æ¯”ä¾‹ï¼Œå¦‚ä¸‹ï¼š\n recall/TPR = TP/(TP+FN)  ä¸Šå…¬å¼ä¸­çš„TP+FNå³ä¸ºæ‰€æœ‰çœŸæ­£ä¸ºæ­£æ ·æœ¬çš„æ•°æ®ï¼Œè€ŒTPä¸ºé¢„æµ‹æ­£ç¡®çš„æ­£æ ·æœ¬ä¸ªæ•°ã€‚\nFPR FPR(false positive rate)ï¼Œå®ƒæ˜¯æŒ‡å®é™…è´Ÿä¾‹ä¸­ï¼Œé”™è¯¯çš„åˆ¤æ–­ä¸ºæ­£ä¾‹çš„æ¯”ä¾‹ï¼Œè¿™ä¸ªå€¼å¾€å¾€è¶Šå°è¶Šå¥½ï¼Œå¦‚ä¸‹ï¼š\n FPR = FP/(FP+TN)  å…¶ä¸­ï¼ŒFP+TNå³ä¸ºå®é™…æ ·æœ¬ä¸­æ‰€æœ‰è´Ÿæ ·æœ¬çš„æ€»å’Œï¼Œè€ŒFPåˆ™æ˜¯æŒ‡åˆ¤æ–­ä¸ºæ­£æ ·æœ¬çš„è´Ÿæ ·æœ¬ã€‚\nF1-Score F1åˆ†æ•°(F1-score)æ˜¯åˆ†ç±»é—®é¢˜çš„ä¸€ä¸ªè¡¡é‡æŒ‡æ ‡ã€‚F1åˆ†æ•°è®¤ä¸ºå¬å›ç‡å’Œç²¾åº¦åŒç­‰é‡è¦, ä¸€äº›å¤šåˆ†ç±»é—®é¢˜çš„æœºå™¨å­¦ä¹ ç«èµ›ï¼Œå¸¸å¸¸å°†F1-scoreä½œä¸ºæœ€ç»ˆæµ‹è¯„çš„æ–¹æ³•ã€‚å®ƒæ˜¯ç²¾ç¡®ç‡å’Œå¬å›ç‡çš„è°ƒå’Œå¹³å‡æ•°ï¼Œæœ€å¤§ä¸º1ï¼Œæœ€å°ä¸º0ã€‚è®¡ç®—å…¬å¼å¦‚ä¸‹ï¼š\n F1 = 2TP/(2TP+FP+FN)  æ­¤å¤–è¿˜æœ‰F2åˆ†æ•°å’ŒF0.5åˆ†æ•°ã€‚F2åˆ†æ•°è®¤ä¸ºå¬å›ç‡çš„é‡è¦ç¨‹åº¦æ˜¯ç²¾åº¦çš„2å€ï¼Œè€ŒF0.5åˆ†æ•°è®¤ä¸ºå¬å›ç‡çš„é‡è¦ç¨‹åº¦æ˜¯ç²¾åº¦çš„ä¸€åŠã€‚è®¡ç®—å…¬å¼ä¸ºï¼š\næ›´ä¸€èˆ¬åœ°ï¼Œæˆ‘ä»¬å¯ä»¥å®šä¹‰Fcï¼ˆprecisionå’Œrecallæƒé‡å¯è°ƒçš„F1 scoreï¼‰:\n Fc = ((1+c*c)*precision*recall) / (c*c*precision + recall)  "},{"uri":"/02extraction.html","title":"åŠ¨æ‰‹å®éªŒ1: åŸºäºAmazon SageMakerè®­ç»ƒä¸€ä¸ªç«¯åˆ°ç«¯æŠ½å–å¼çš„ABSAæ¨¡å‹","tags":[],"description":"","content":"è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨ä¸¤ç§æ¨¡å‹ä½œä¸ºæ¼”ç¤ºç”¨:   LCF-ATEPC paper - A Multi-task Learning Model for Chinese-oriented Aspect Polarity Classification and Aspect Term Extractionã€‚\n  CAS-Bert paper - Utilizing BERT for Aspect-Based Sentiment Analysis via Constructing Auxiliary Sentence\u0026quot; (NAACL 2019)ã€‚ è¿™ä¸ªæ–¹æ³•çš„è¾“å…¥è¾“å‡ºè®¾è®¡å¾ˆç¬¦åˆTABSAä»»åŠ¡ï¼Œåšæ³•ç®€å•ï¼Œé€‚åˆä½œä¸ºæ­¤ç±»ä»»åŠ¡çš„baseline.\n  SOTA for ate taskï¼š https://paperswithcode.com/sota/aspect-based-sentiment-analysis-on-semeval?p=a-multi-task-learning-model-for-chinese æˆ‘ä»¬ç°åœ¨ä¼šç”¨sagemakerè¿›è¡Œä¸€ä¸ªæ¨¡å‹çš„æœ¬åœ°è®­ç»ƒï¼Œä½¿ç”¨ml.p3.8xlargeæœºå‹ã€‚\nLCF-ATEPC  æ ¸å¿ƒè´¡çŒ®ï¼š  æå‡ºå±€éƒ¨ä¸Šä¸‹æ–‡èšç„¦ï¼ˆCDM/CDWï¼‰æœºåˆ¶ï¼Œä½¿å¾—self-attentionå¾—åˆ°çš„ç‰¹å¾èšç„¦äºaspecté™„è¿‘\nCAS-Bert æ ¸å¿ƒæ€æƒ³ä¸ºå°†å®é™…æ ‡ç­¾ä¸­çš„(aspect term, aspect category, sentiment)ä¸‰å…ƒç»„ç”Ÿæˆè¾…åŠ©å¥ï¼Œç„¶ååšè¾“å…¥è¯„è®ºå’Œè¾…åŠ©å¥çš„matchingï¼Œç›¸å½“äºå¥å­çº§åˆ«çš„åˆ†ç±»ä»»åŠ¡ã€‚\nä»¥QA-Bæ¨¡å¼ä¸ºä¾‹ï¼š å®é™…labelä¸º(aspect term, aspect category, sentiment) åˆ™å¯¹safetyè¿™ä¸ªcategoryç”Ÿæˆä¸‰å¥è¯ï¼š\n the sentiment of the aspect safety of aspect term is positive the sentiment of the aspect safety of aspect term is none the sentiment of the aspect safety of aspect term is negative  ç„¶ååšå®é™…è¯„è®ºå’Œç”Ÿæˆè¾…åŠ©å¥çš„åˆ†ç±»ä»»åŠ¡\n"},{"uri":"/02extraction/01train.html","title":"æŠ½å–å¼ABSAæ¨¡å‹è®­ç»ƒ1","tags":[],"description":"","content":"paper - A Multi-task Learning Model for Chinese-oriented Aspect Polarity Classification and Aspect Term Extractionã€‚\nSOTA for ate taskï¼š https://paperswithcode.com/sota/aspect-based-sentiment-analysis-on-semeval?p=a-multi-task-learning-model-for-chinese æˆ‘ä»¬ç°åœ¨ä¼šç”¨sagemakerè¿›è¡Œä¸€ä¸ªæ¨¡å‹çš„æœ¬åœ°è®­ç»ƒï¼Œä½¿ç”¨ml.p3.8xlargeæœºå‹ã€‚\næ•°æ®å‡†å¤‡ é¦–å…ˆä¸‹è½½ä»£ç \nsource activate pytorch_p37 cd SageMaker git clone https://github.com/jackie930/PyABSA.git å°†æ•°æ®data1119.csvä¸Šä¼ åˆ°PyABSA/data/data1109.csv\næ¨¡å‹è®­ç»ƒ æ•°æ®å‡†å¤‡\ncd PyABSA pip install termcolor update_checker findfile jupyterlab-git torch==1.10.0 transformers==4.12.3 autocuda spacy googledrivedownloader seqeval emoji python pyabsa/utils/preprocess.py --inpath './data/data1109.csv' --folder_name 'custom_atepc_1109' --task 'aptepc' ç„¶åè¿›è¡Œæ¨¡å‹è®­ç»ƒï¼Œæ¼”ç¤ºç›®çš„ï¼Œåªè®­ç»ƒä¸€ä¸ªepoch\nfrom pyabsa.functional import ATEPCModelList from pyabsa.functional import Trainer, ATEPCTrainer from pyabsa.functional import ATEPCConfigManager atepc_config_custom = ATEPCConfigManager.get_atepc_config_chinese() atepc_config_custom.num_epoch = 2 atepc_config_custom.evaluate_begin = 1 atepc_config_custom.log_step = 100 atepc_config_custom.model = ATEPCModelList.LCF_ATEPC aspect_extractor = ATEPCTrainer(config=atepc_config_custom, dataset=\u0026#39;./custom_atepc_1109\u0026#39; ) è®­ç»ƒå®Œæˆåï¼Œæ¨¡å‹è¯„ä¼°\npython utils/metrics_cacl.py --data_path --checkppoint "},{"uri":"/03generative/0501train.html","title":"ç”Ÿæˆå¼çš„ABSAæ¨¡å‹è®­ç»ƒ","tags":[],"description":"","content":"æˆ‘ä»¬ç°åœ¨ä¼šç”¨sagemakerè¿›è¡Œä¸€ä¸ªç”Ÿæˆå¼çš„ABSAæ¨¡å‹çš„æœ¬åœ°è®­ç»ƒï¼Œä½¿ç”¨ML.P3.2xlargeæœºå‹ã€‚\næ•°æ®å‡†å¤‡ é¦–å…ˆä¸‹è½½ä»£ç \ncd SageMaker git clone https://github.com/HaoranLv/Generative-ABSA-SageMaker.git å®‰è£…ç¯å¢ƒ\nsource activate pytorch_p37 pip install -r requirements.txt ç„¶åå¤„ç†æ•°æ®data_prepare.ipynbï¼Œè¿›è¡Œæ•°æ®æ¸…æ´—å¹¶åˆ‡åˆ†train/testã€‚ æ³¨æ„è¿™é‡Œï¼Œä¸ºäº†å¿«é€Ÿäº§ç”Ÿç»“æœï¼Œæˆ‘ä»¬åªè¦ç”¨800æ¡æ•°æ®è®­ç»ƒï¼Œ200æ¡æµ‹è¯•/éªŒè¯\ndf=pd.read_csv('data/ctrip/data1119_part.csv') write_txt(df,path='data/ctrip/total.txt') write_train_test(train_path='data/ctrip/train.txt',test_path='data/ctrip/test.txt',root='data/ctrip/total1119.txt') æ¨¡å‹è®­ç»ƒ æ¥ä¸‹æ¥æˆ‘ä»¬è¿è¡Œè®­ç»ƒ,è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨huggingfaceä¸Šçš„å…¬å¼€çš„lemon234071/t5-base-Chineseä½œä¸ºè®­ç»ƒèµ·ç‚¹ï¼Œä¸ºäº†æ¼”ç¤ºç›®çš„ï¼Œæˆ‘ä»¬åªè¿è¡Œä¸€ä¸ªepochï¼Œå¤§çº¦éœ€è¦5min\npython -u main.py --task tasd-cn \\ --dataset ctrip \\ --paradigm extraction \\ --n_gpu '0' \\ --model_name_or_path lemon234071/t5-base-Chinese \\ --do_train \\ --train_batch_size 2 \\ --gradient_accumulation_steps 2 \\ --eval_batch_size 2 \\ --learning_rate 3e-4 \\ --num_train_epochs 1 \u0026gt; logs/noemj_lr3e-4.log è®­ç»ƒå®Œæˆåï¼Œä¼šæç¤ºæ—¥å¿—ä¿¡æ¯å¦‚ä¸‹\nFinish training and saving the model! æ¨¡å‹ç»“æœæ–‡ä»¶åŠç›¸åº”çš„æ—¥å¿—ç­‰ä¿¡æ¯ä¼šè‡ªåŠ¨ä¿å­˜åœ¨./outputs/tasd-cn/ctrip/extraction/\nç»“æœæœ¬åœ°éªŒè¯ æˆ‘ä»¬å¯ä»¥ç›´æ¥ç”¨è¿™ä¸ªäº§ç”Ÿçš„æ¨¡å‹æ–‡ä»¶è¿›è¡Œæœ¬åœ°æ¨ç†ã€‚æ³¨æ„è¿™é‡Œçš„æ¨¡å‹æ–‡ä»¶åœ°å€çš„æŒ‡å®šä¸ºä½ åˆšåˆšè®­ç»ƒäº§ç”Ÿçš„ã€‚\npython main.py --task tasd-cn \\ --dataset ctrip \\ --ckpoint_path outputs/tasd-cn/ctrip/extraction/cktepoch=1.ckpt \\ --paradigm extraction \\ --n_gpu '0' \\ --do_direct_eval \\ --eval_batch_size 128 \\ ç»“æœæœ¬åœ°æµ‹è¯• æˆ‘ä»¬å¯ä»¥ç›´æ¥ç”¨è¿™ä¸ªäº§ç”Ÿçš„æ¨¡å‹æ–‡ä»¶è¿›è¡Œæœ¬åœ°æ¨ç†ã€‚æ³¨æ„è¿™é‡Œçš„æ¨¡å‹æ–‡ä»¶åœ°å€çš„æŒ‡å®šä¸ºä½ åˆšåˆšè®­ç»ƒäº§ç”Ÿçš„ã€‚\npython main.py --task tasd-cn \\ --dataset ctrip \\ --ckpoint_path outputs/tasd-cn/ctrip/extraction/cktepoch=1.ckpt \\ --text æ—©é¤ä¸€èˆ¬èˆ¬ï¼Œå‹‰å‹‰å¼ºå¼ºå¡«é¥±è‚šå­ï¼Œæ ·å¼å¯é€‰æ€§ä¸å¤šï¼Œå¯èƒ½æ˜¯ç–«æƒ…çš„å½±å“å§ã€‚ä¸è¿‡é…’åº—çš„æœåŠ¡ä¸é”™ï¼Œäº”ä¸ªå°å­©æ—©é¤éƒ½é€äº†ï¼Œç‚¹ğŸ‘ã€‚ç”±äºé…’åº—å†å²æœ‰ç‚¹é•¿ï¼Œæ‰€ä»¥è®¾æ–½æ„Ÿè§‰ä¸€èˆ¬èˆ¬ï¼Œæ•´ä½“è¿˜å¯ä»¥ï¼Œä¸‰é’»å§ \\ --paradigm extraction \\ --n_gpu 0 \\ --do_direct_predict \\ è¾“å‡ºå¦‚ä¸‹\nsents: æ—©é¤ä¸€èˆ¬èˆ¬ï¼Œå‹‰å‹‰å¼ºå¼ºå¡«é¥±è‚šå­ï¼Œæ ·å¼å¯é€‰æ€§ä¸å¤šï¼Œå¯èƒ½æ˜¯ç–«æƒ…çš„å½±å“å§ã€‚ä¸è¿‡é…’åº—çš„æœåŠ¡ä¸é”™ï¼Œäº”ä¸ªå°å­©æ—©é¤éƒ½é€äº†ï¼Œç‚¹ğŸ‘ã€‚ç”±äºé…’åº—å†å²æœ‰ç‚¹é•¿ï¼Œæ‰€ä»¥è®¾æ–½æ„Ÿè§‰ä¸€èˆ¬èˆ¬ï¼Œæ•´ä½“è¿˜å¯ä»¥ï¼Œä¸‰é’»å§ pred: 0.5794262886047363 ç”±äºæ ·æœ¬æ•°æ®ä¸­ç©ºè¾“å‡ºè¾ƒå¤šï¼Œä¸”ä»…è®­ç»ƒäº†ä¸€ä¸ªepochæ•…æ¨¡å‹å€¾å‘äºè¾“å‡ºç©º\nåˆ°è¿™é‡Œï¼Œå°±å®Œæˆäº†ä¸€ä¸ªæ¨¡å‹çš„è®­ç»ƒè¿‡ç¨‹ã€‚\n"},{"uri":"/02extraction/02train.html","title":"æŠ½å–å¼ABSAæ¨¡å‹è®­ç»ƒ2","tags":[],"description":"","content":"paper - Utilizing BERT for Aspect-Based Sentiment Analysis via Constructing Auxiliary Sentence\u0026quot; (NAACL 2019)ã€‚ è¿™ä¸ªæ–¹æ³•çš„è¾“å…¥è¾“å‡ºè®¾è®¡å¾ˆç¬¦åˆTABSAä»»åŠ¡ï¼Œåšæ³•ç®€å•ï¼Œé€‚åˆä½œä¸ºæ­¤ç±»ä»»åŠ¡çš„baseline.\næˆ‘ä»¬ç°åœ¨ä¼šç”¨sagemakerè¿›è¡Œä¸€ä¸ªæ¨¡å‹çš„æœ¬åœ°è®­ç»ƒï¼Œä½¿ç”¨ml.p3.8xlargeæœºå‹ã€‚\næ•°æ®å‡†å¤‡ é¦–å…ˆä¸‹è½½ä»£ç \nsource activate pytorch_p37 cd SageMaker git clone https://github.com/jackie930/ABSA-BERT-pair.git å°†æ•°æ®data1119.csvä¸Šä¼ åˆ°data/custom/data1119.csv\næ¨¡å‹è®­ç»ƒ æ¥ä¸‹æ¥æˆ‘ä»¬è¿è¡Œè®­ç»ƒï¼Œé¦–å…ˆä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹å¹¶è½¬æ¢ä¸ºtorchç‰ˆæœ¬\ncd ABSA-BERT-pair wget -P ./source/bert/pretrain_model/cn https://storage.googleapis.com/bert_models/2018_11_03/chinese_L-12_H-768_A-12.zip cd ./source/bert/pretrain_model/cn unzip chinese_L-12_H-768_A-12.zip pip install tensorflow==1.13.1 cd /home/ec2-user/SageMaker/ABSA-BERT-pair/ python convert_tf_checkpoint_to_pytorch.py \\ --tf_checkpoint_path ./source/bert/pretrain_model/cn/chinese_L-12_H-768_A-12/bert_model.ckpt \\ --bert_config_file ./source/bert/pretrain_model/cn/chinese_L-12_H-768_A-12/bert_config.json \\ --pytorch_dump_path ./source/bert/pretrain_model/cn/pytorch_model.bin æ•°æ®å‡†å¤‡\ncd generate/ python generate_custom_NLI_M.py ç„¶åè¿›è¡Œæ¨¡å‹è®­ç»ƒï¼Œæ¼”ç¤ºç›®çš„ï¼Œåªè®­ç»ƒä¸€ä¸ªepoch\ncd ../ CUDA_VISIBLE_DEVICES=0,1,2,3 python run_classifier_TABSA-v1.py \\ --task_name custom_NLI_M \\ --data_dir data/custom/bert-pair/ \\ --vocab_file ./source/bert/pretrain_model/cn/chinese_L-12_H-768_A-12/vocab.txt \\ --bert_config_file ./source/bert/pretrain_model/cn/chinese_L-12_H-768_A-12/bert_config.json \\ --init_checkpoint ./source/bert/pretrain_model/cn/pytorch_model.bin \\ --eval_test \\ --do_lower_case \\ --max_seq_length 512 \\ --train_batch_size 48 \\ --learning_rate 2e-5 \\ --num_train_epochs 1.0 \\ --do_save_model \\ --output_dir results/custom/NLI_M \\ --seed 42 è®­ç»ƒå®Œæˆåï¼Œæ¨¡å‹è¯„ä¼°\npython evaluation.py --task_name custom_NLI_M --pred_data_dir results/custom/NLI_M/test_ep_1.txt "},{"uri":"/03generative.html","title":"åŠ¨æ‰‹å®éªŒ2: åŸºäºAmazon SageMakerè®­ç»ƒä¸€ä¸ªç«¯åˆ°ç«¯ç”Ÿæˆå¼çš„ABSAæ¨¡å‹ä»¥åŠéƒ¨ç½²","tags":[],"description":"","content":"Generation-ABSA paper - Towards Generative Aspect-Based Sentiment Analysis (ACL 2021)\næ¨¡å‹æ¶æ„ å°†å®Œæ•´çš„ABSAä»»åŠ¡é‡æ–°å®šä¹‰ä¸ºåºåˆ—ç”Ÿæˆä»»åŠ¡ï¼Œå¹¶ç»™å‡ºä¸¤ç§è®­ç»ƒæ¨¡å¼ åˆ†è§£ABSAä»»åŠ¡ä¸ºAspect Opinion Pair Extraction (AOPE)ã€UnifiedABSA (UABSA), spect Sentiment Triplet Extrac-tion (ASTE), Target Aspect Sentiment Detec-tion (TASD) ä»»åŠ¡å¤„ç†ï¼Œæ‰€æœ‰å­ä»»åŠ¡å‡ç”¨åŒæ ·çš„è®­ç»ƒæ¨¡å¼è®­ç»ƒ\næ¨¡å‹è¡¨ç° "},{"uri":"/03generative/0503deploy.html","title":"ç”Ÿæˆå¼ABSAæ¨¡å‹éƒ¨ç½²","tags":[],"description":"","content":"é¦–å…ˆæ‰“åŒ…é•œåƒå¹¶æ¨é€\ncd endpoint sh build_and_push.sh generative-absa ç„¶åéƒ¨ç½²ä¸€ä¸ªé¢„ç½®çš„endpoint\n#æ³¨æ„ä¿®æ”¹ï¼š847380964353.dkr.ecr.ap-northeast-1.amazonaws.com/generative-absaä¸ºè‡ªå·±å¯¹åº”çš„ !python create_endpoint.py \\ --endpoint_ecr_image_path \u0026#34;847380964353.dkr.ecr.ap-northeast-1.amazonaws.com/generative-absa\u0026#34; \\ --endpoint_name \u0026#39;generative-absa\u0026#39; \\ --instance_type \u0026#34;ml.p3.2xlarge\u0026#34; è¾“å‡º\nmodel_name: generative-absa endpoint_ecr_image_path: 847380964353.dkr.ecr.ap-northeast-1.amazonaws.com/generative-absa \u0026lt;\u0026lt;\u0026lt; Completed model endpoint deployment. generative-absa å½“çŠ¶æ€å˜ä¸ºInServiceå³ä»£è¡¨éƒ¨ç½²å®Œæˆ\nåœ¨éƒ¨ç½²ç»“æŸåï¼Œçœ‹åˆ°SageMakeræ§åˆ¶å°ç”Ÿæˆäº†å¯¹åº”çš„endpoint,å¯ä»¥ä½¿ç”¨å¦‚ä¸‹å®¢æˆ·ç«¯ä»£ç æµ‹è¯•è°ƒç”¨\n%%time from boto3.session import Session import json data={\u0026#34;data\u0026#34;: \u0026#39;æ—©é¤ä¸€èˆ¬èˆ¬ï¼Œå‹‰å‹‰å¼ºå¼ºå¡«é¥±è‚šå­ï¼Œæ ·å¼å¯é€‰æ€§ä¸å¤šï¼Œå¯èƒ½æ˜¯ç–«æƒ…çš„å½±å“å§ã€‚ä¸è¿‡é…’åº—çš„æœåŠ¡ä¸é”™ï¼Œäº”ä¸ªå°å­©æ—©é¤éƒ½é€äº†ï¼Œç‚¹ğŸ‘ã€‚ç”±äºé…’åº—å†å²æœ‰ç‚¹é•¿ï¼Œæ‰€ä»¥è®¾æ–½æ„Ÿè§‰ä¸€èˆ¬èˆ¬ï¼Œæ•´ä½“è¿˜å¯ä»¥ï¼Œä¸‰é’»å§\u0026#39;} session = Session() runtime = session.client(\u0026#34;runtime.sagemaker\u0026#34;) response = runtime.invoke_endpoint( EndpointName=\u0026#39;absa\u0026#39;, ContentType=\u0026#34;application/json\u0026#34;, Body=json.dumps(data), ) result = json.loads(response[\u0026#34;Body\u0026#34;].read()) print (result) ç»“æœå¦‚ä¸‹\n{'result': '(å°å­©æ—©é¤, å„¿ç«¥é¤é¥®, é€äº†ç‚¹ğŸ‘, æ­£)', 'infer_time': '0:00:00.725859'} "},{"uri":"/categories.html","title":"Categories","tags":[],"description":"","content":""},{"uri":"/tags.html","title":"Tags","tags":[],"description":"","content":""}]