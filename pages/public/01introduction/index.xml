<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Introduction on SpotBot Workshop</title><link>/01introduction.html</link><description>Recent content in Introduction on SpotBot Workshop</description><generator>Hugo -- gohugo.io</generator><language>en-US</language><lastBuildDate>Fri, 05 Nov 2021 14:52:27 +0800</lastBuildDate><atom:link href="/01introduction/index.xml" rel="self" type="application/rss+xml"/><item><title>1.1 算法概述</title><link>/01introduction/100algorithm.html</link><pubDate>Fri, 05 Nov 2021 14:52:27 +0800</pubDate><guid>/01introduction/100algorithm.html</guid><description>使用场景 根据任务定义方式可以分为端到端式ABSA和pipeline式ABSA。
pipeline式ABSA：通过不同的模型组件分别完成AE,APC等任务后搭建成一个pipeline组合输出。 端到端式ABSA：通过一个模型直接完成ABSA所定义的全部或者多个任务。 pipeline式ABSA 端到端式ABSA 业内做法 AE Aspect term extraction with history attention and selective transformation(IJCAI 2019) Double embeddings and cnn-based sequence labeling for aspect extraction(ACL 2018)
SC Aspect level sentiment classification with deep memory net-work(EMNLP 2016) Relational Graph Attention Network for Aspect-based Sentiment Analysis(ACL 2020)
OE Coupled multi-layer attentions for co-extraction of aspect and opinion terms(AAAI 2017)
Unified framework A unified model for opinion target extraction and target sentiment prediction(AAAI 2019) An interactive multi-task learning network for end-to-end aspect-based sentiment analysis (ACL 2019) DOER: dual cross-shared RNN for aspect term-polarity co-extraction (ACL 2019)</description></item><item><title>1.2 数据集</title><link>/01introduction/200data.html</link><pubDate>Fri, 05 Nov 2021 14:52:27 +0800</pubDate><guid>/01introduction/200data.html</guid><description>1.公开数据集 (英文)及其标注样例 2.公开数据集 (中文) 北大 (https://github.com/NLPBLCU/Chinese-Multi-Target-Sentiment-Classification-Dataset/blob/master/our_data.7z) 2K条数据，6K个aspect 美团 (https://raw.githubusercontent.com/viewlei/fsauor2018/master/src/sentiment_analysis_trainingset_annotations.pdf) 包含105000条训练样本以及15000条测试样本 ，两层aspect共20种aspect, 即传统的多分类问题</description></item><item><title>1.3 评估指标</title><link>/01introduction/300metrics.html</link><pubDate>Fri, 05 Nov 2021 14:52:27 +0800</pubDate><guid>/01introduction/300metrics.html</guid><description>目前的ABSA采用类似分类任务的评估指标作为评估 准确率/精度/召回率/FPR/F1指标 以上五个指标都离不开下列定义：
预测值为正例，记为P（Positive） 预测值为反例，记为N（Negative） 预测值与真实值相同，记为T（True） 预测值与真实值相反，记为F（False） 准确率 准确率accuracy是我们最常见的评价指标，这个很容易理解，就是被分对的样本数除以所有的样本数，通常来说，正确率越高，分类器越好，如下：
accuracy = (TP+TN)/(TP+TN+FP+FN) 上公式中的TP+TN即为所有的正确预测为正样本的数据与正确预测为负样本的数据的总和，TP+TN+FP+FN即为总样本的个数。
精度 精度precision是从预测结果的角度来统计的，是说预测为正样本的数据中，有多少个是真正的正样本，即“找的对”的比例，如下：
precision = TP/( TP+FP) 上公式中的TP+FP即为所有的预测为正样本的数据，TP即为预测正确的正样本个数。
召回率/TPR 召回率recall和TPR(灵敏度(true positive rate))是一个概念，都是从真实的样本集来统计的，是说在总的正样本中，模型找回了多少个正样本，即“找的全”的比例，如下：
recall/TPR = TP/(TP+FN) 上公式中的TP+FN即为所有真正为正样本的数据，而TP为预测正确的正样本个数。
FPR FPR(false positive rate)，它是指实际负例中，错误的判断为正例的比例，这个值往往越小越好，如下：
FPR = FP/(FP+TN) 其中，FP+TN即为实际样本中所有负样本的总和，而FP则是指判断为正样本的负样本。
F1-Score F1分数(F1-score)是分类问题的一个衡量指标。F1分数认为召回率和精度同等重要, 一些多分类问题的机器学习竞赛，常常将F1-score作为最终测评的方法。它是精确率和召回率的调和平均数，最大为1，最小为0。计算公式如下：
F1 = 2TP/(2TP+FP+FN) 此外还有F2分数和F0.5分数。F2分数认为召回率的重要程度是精度的2倍，而F0.5分数认为召回率的重要程度是精度的一半。计算公式为：
更一般地，我们可以定义Fc（precision和recall权重可调的F1 score）:
Fc = ((1+c*c)*precision*recall) / (c*c*precision + recall)</description></item></channel></rss>