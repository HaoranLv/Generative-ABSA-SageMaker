---
title: "1.3 评估指标"
date: 2021-11-05T14:52:27+08:00
weight: 0240
draft: false
---

###  目前的ABSA采用类似分类任务的评估指标作为评估

### 准确率/精度/召回率/FPR/F1指标

以上五个指标都离不开下列定义：

* 预测值为正例，记为P（Positive）
* 预测值为反例，记为N（Negative）
* 预测值与真实值相同，记为T（True）
* 预测值与真实值相反，记为F（False）

# 准确率

准确率accuracy是我们最常见的评价指标，这个很容易理解，就是被分对的样本数除以所有的样本数，通常来说，正确率越高，分类器越好，如下：

        accuracy = (TP+TN)/(TP+TN+FP+FN)

上公式中的TP+TN即为所有的正确预测为正样本的数据与正确预测为负样本的数据的总和，TP+TN+FP+FN即为总样本的个数。

# 精度

精度precision是从预测结果的角度来统计的，是说预测为正样本的数据中，有多少个是真正的正样本，即“找的对”的比例，如下：

         precision = TP/( TP+FP)

上公式中的TP+FP即为所有的预测为正样本的数据，TP即为预测正确的正样本个数。

# 召回率/TPR

召回率recall和TPR(灵敏度(true positive rate))是一个概念，都是从真实的样本集来统计的，是说在总的正样本中，模型找回了多少个正样本，即“找的全”的比例，如下：

         recall/TPR  = TP/(TP+FN)

上公式中的TP+FN即为所有真正为正样本的数据，而TP为预测正确的正样本个数。

# FPR

FPR(false positive rate)，它是指实际负例中，错误的判断为正例的比例，这个值往往越小越好，如下：

         FPR = FP/(FP+TN)

其中，FP+TN即为实际样本中所有负样本的总和，而FP则是指判断为正样本的负样本。

# F1-Score

F1分数(F1-score)是分类问题的一个衡量指标。F1分数认为召回率和精度同等重要, 一些多分类问题的机器学习竞赛，常常将F1-score作为最终测评的方法。它是精确率和召回率的调和平均数，最大为1，最小为0。计算公式如下：

         F1 = 2TP/(2TP+FP+FN)

此外还有F2分数和F0.5分数。F2分数认为召回率的重要程度是精度的2倍，而F0.5分数认为召回率的重要程度是精度的一半。计算公式为：

更一般地，我们可以定义Fc（precision和recall权重可调的F1 score）:

        Fc = ((1+c*c)*precision*recall) / (c*c*precision + recall)

