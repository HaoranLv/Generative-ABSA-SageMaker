[{"uri":"/","title":"AWS Datalab-细粒度情感分析","tags":[],"description":"","content":"Author\n JUNYI LIU (AWS GCR Applied Scientist)  概述 本次workshop分为几个部分\n 背景介绍- what is text summary？ 基于Amazon SageMaker的TEXTRANK模型训练动手实验 基于Amazon SageMaker的Huggingface训练一个BART英文摘要模型  模型训练ß 模型部署   基于Amazon SageMaker的MT5模型训练动手实验  本地模型训练 启动模型训练任务 模型部署   基于Amazon SageMaker的CPT模型训练动手实验  模型训练 模型增强训练 模型部署    本次 workshop 前提 本次 workshop 建议在 US-WEST-2 Region 使用。为了演示方便，所以本 workshop 所有的演示都会以US-WEST-2 Region 为例。\n"},{"uri":"/01introduction.html","title":"Introduction","tags":[],"description":"","content":"细粒度情感分析任务（ABSA） 对于一句餐馆评论：“Waiters are very friendly and the pasta is simply average.”，提到了两个评论目标：“waiter”和“pasta”；用来评价他们的词分别是：“friendly”和“average”；这句话评论的分别是餐馆的“service”和“food”方面。\n从目标识别角度，针对 aspect term 和 opinion term，存在抽取问题；针对 aspect category，存在分类问题（假设预定义 aspect categories）。从情感分析角度，对 aspect term 和 aspect category 存在情感分类问题。这些原子任务如下图中间层所示。注意，一句评论里可能没有显示提及 aspect term，但同样可以存在 aspect category，比如“I was treated rudely.”讲的是“service”。\n"},{"uri":"/01introduction/100algorithm.html","title":"1.1 算法概述","tags":[],"description":"","content":"使用场景 根据任务定义方式可以分为端到端式ABSA和pipeline式ABSA。\n pipeline式ABSA：通过不同的模型组件分别完成AE,APC等任务后搭建成一个pipeline组合输出。 端到端式ABSA：通过一个模型直接完成ABSA所定义的全部或者多个任务。  pipeline式ABSA 端到端式ABSA 业内做法 AE Aspect term extraction with history attention and selective transformation(IJCAI 2019) Double embeddings and cnn-based sequence labeling for aspect extraction(ACL 2018)\nSC Aspect level sentiment classification with deep memory net-work(EMNLP 2016) Relational Graph Attention Network for Aspect-based Sentiment Analysis(ACL 2020)\nOE Coupled multi-layer attentions for co-extraction of aspect and opinion terms(AAAI 2017)\nUnified framework A unified model for opinion target extraction and target sentiment prediction(AAAI 2019) An interactive multi-task learning network for end-to-end aspect-based sentiment analysis (ACL 2019) DOER: dual cross-shared RNN for aspect term-polarity co-extraction (ACL 2019)\nGeneral framework Relation-Aware Collaborative Learning for Unified Aspect-Based Sentiment Analysis(ACL 2020) Towards Generative Aspect-Based Sentiment Analysis(ACL 2021)\n"},{"uri":"/01introduction/200data.html","title":"1.2 数据集","tags":[],"description":"","content":"1.公开数据集 (英文)及其标注样例 2.公开数据集 (中文)  北大 (https://github.com/NLPBLCU/Chinese-Multi-Target-Sentiment-Classification-Dataset/blob/master/our_data.7z) 2K条数据，6K个aspect 美团 (https://raw.githubusercontent.com/viewlei/fsauor2018/master/src/sentiment_analysis_trainingset_annotations.pdf) 包含105000条训练样本以及15000条测试样本 ，两层aspect共20种aspect, 即传统的多分类问题  "},{"uri":"/01introduction/300metrics.html","title":"1.3 评估指标","tags":[],"description":"","content":"目前的ABSA采用类似分类任务的评估指标作为评估 准确率/精度/召回率/FPR/F1指标 以上五个指标都离不开下列定义：\n 预测值为正例，记为P（Positive） 预测值为反例，记为N（Negative） 预测值与真实值相同，记为T（True） 预测值与真实值相反，记为F（False）  准确率 准确率accuracy是我们最常见的评价指标，这个很容易理解，就是被分对的样本数除以所有的样本数，通常来说，正确率越高，分类器越好，如下：\n accuracy = (TP+TN)/(TP+TN+FP+FN)  上公式中的TP+TN即为所有的正确预测为正样本的数据与正确预测为负样本的数据的总和，TP+TN+FP+FN即为总样本的个数。\n精度 精度precision是从预测结果的角度来统计的，是说预测为正样本的数据中，有多少个是真正的正样本，即“找的对”的比例，如下：\n precision = TP/( TP+FP)  上公式中的TP+FP即为所有的预测为正样本的数据，TP即为预测正确的正样本个数。\n召回率/TPR 召回率recall和TPR(灵敏度(true positive rate))是一个概念，都是从真实的样本集来统计的，是说在总的正样本中，模型找回了多少个正样本，即“找的全”的比例，如下：\n recall/TPR = TP/(TP+FN)  上公式中的TP+FN即为所有真正为正样本的数据，而TP为预测正确的正样本个数。\nFPR FPR(false positive rate)，它是指实际负例中，错误的判断为正例的比例，这个值往往越小越好，如下：\n FPR = FP/(FP+TN)  其中，FP+TN即为实际样本中所有负样本的总和，而FP则是指判断为正样本的负样本。\nF1-Score F1分数(F1-score)是分类问题的一个衡量指标。F1分数认为召回率和精度同等重要, 一些多分类问题的机器学习竞赛，常常将F1-score作为最终测评的方法。它是精确率和召回率的调和平均数，最大为1，最小为0。计算公式如下：\n F1 = 2TP/(2TP+FP+FN)  此外还有F2分数和F0.5分数。F2分数认为召回率的重要程度是精度的2倍，而F0.5分数认为召回率的重要程度是精度的一半。计算公式为：\n更一般地，我们可以定义Fc（precision和recall权重可调的F1 score）:\n Fc = ((1+c*c)*precision*recall) / (c*c*precision + recall)  "},{"uri":"/02extraction.html","title":"动手实验1: 基于Amazon SageMaker训练一个端到端抽取式的ABSA模型","tags":[],"description":"","content":"这里我们使用两种模型作为演示用:   LCF-ATEPC paper - A Multi-task Learning Model for Chinese-oriented Aspect Polarity Classification and Aspect Term Extraction。\n  CAS-Bert paper - Utilizing BERT for Aspect-Based Sentiment Analysis via Constructing Auxiliary Sentence\u0026quot; (NAACL 2019)。 这个方法的输入输出设计很符合TABSA任务，做法简单，适合作为此类任务的baseline.\n  SOTA for ate task： https://paperswithcode.com/sota/aspect-based-sentiment-analysis-on-semeval?p=a-multi-task-learning-model-for-chinese 我们现在会用sagemaker进行一个模型的本地训练，使用ml.p3.8xlarge机型。\nLCF-ATEPC  核心贡献：  提出局部上下文聚焦（CDM/CDW）机制，使得self-attention得到的特征聚焦于aspect附近\nCAS-Bert 核心思想为将实际标签中的(aspect term, aspect category, sentiment)三元组生成辅助句，然后做输入评论和辅助句的matching，相当于句子级别的分类任务。\n以QA-B模式为例： 实际label为(aspect term, aspect category, sentiment) 则对safety这个category生成三句话：\n the sentiment of the aspect safety of aspect term is positive the sentiment of the aspect safety of aspect term is none the sentiment of the aspect safety of aspect term is negative  然后做实际评论和生成辅助句的分类任务\n"},{"uri":"/02extraction/01train.html","title":"抽取式ABSA模型训练1","tags":[],"description":"","content":"paper - A Multi-task Learning Model for Chinese-oriented Aspect Polarity Classification and Aspect Term Extraction。\nSOTA for ate task： https://paperswithcode.com/sota/aspect-based-sentiment-analysis-on-semeval?p=a-multi-task-learning-model-for-chinese 我们现在会用sagemaker进行一个模型的本地训练，使用ml.p3.8xlarge机型。\n数据准备 首先下载代码\nsource activate pytorch_p37 cd SageMaker git clone https://github.com/jackie930/PyABSA.git 将数据data1119.csv上传到PyABSA/data/data1109.csv\n模型训练 数据准备\ncd PyABSA pip install termcolor update_checker findfile jupyterlab-git torch==1.10.0 transformers==4.12.3 autocuda spacy googledrivedownloader seqeval emoji python pyabsa/utils/preprocess.py --inpath './data/data1109.csv' --folder_name 'custom_atepc_1109' --task 'aptepc' 然后进行模型训练，演示目的，只训练一个epoch\nfrom pyabsa.functional import ATEPCModelList from pyabsa.functional import Trainer, ATEPCTrainer from pyabsa.functional import ATEPCConfigManager atepc_config_custom = ATEPCConfigManager.get_atepc_config_chinese() atepc_config_custom.num_epoch = 2 atepc_config_custom.evaluate_begin = 1 atepc_config_custom.log_step = 100 atepc_config_custom.model = ATEPCModelList.LCF_ATEPC aspect_extractor = ATEPCTrainer(config=atepc_config_custom, dataset=\u0026#39;./custom_atepc_1109\u0026#39; ) 训练完成后，模型评估\npython utils/metrics_cacl.py --data_path --checkppoint "},{"uri":"/03generative/0501train.html","title":"生成式的ABSA模型训练","tags":[],"description":"","content":"我们现在会用sagemaker进行一个生成式的ABSA模型的本地训练，使用ML.P3.2xlarge机型。\n数据准备 首先下载代码\ncd SageMaker git clone https://github.com/HaoranLv/Generative-ABSA-SageMaker.git 安装环境\nsource activate pytorch_p37 pip install -r requirements.txt 然后处理数据data_prepare.ipynb，进行数据清洗并切分train/test。 注意这里，为了快速产生结果，我们只要用800条数据训练，200条测试/验证\ndf=pd.read_csv('data/ctrip/data1119_part.csv') write_txt(df,path='data/ctrip/total.txt') write_train_test(train_path='data/ctrip/train.txt',test_path='data/ctrip/test.txt',root='data/ctrip/total1119.txt') 模型训练 接下来我们运行训练,这里我们使用huggingface上的公开的lemon234071/t5-base-Chinese作为训练起点，为了演示目的，我们只运行一个epoch，大约需要5min\npython -u main.py --task tasd-cn \\ --dataset ctrip \\ --paradigm extraction \\ --n_gpu '0' \\ --model_name_or_path lemon234071/t5-base-Chinese \\ --do_train \\ --train_batch_size 2 \\ --gradient_accumulation_steps 2 \\ --eval_batch_size 2 \\ --learning_rate 3e-4 \\ --num_train_epochs 1 \u0026gt; logs/noemj_lr3e-4.log 训练完成后，会提示日志信息如下\nFinish training and saving the model! 模型结果文件及相应的日志等信息会自动保存在./outputs/tasd-cn/ctrip/extraction/\n结果本地验证 我们可以直接用这个产生的模型文件进行本地推理。注意这里的模型文件地址的指定为你刚刚训练产生的。\npython main.py --task tasd-cn \\ --dataset ctrip \\ --ckpoint_path outputs/tasd-cn/ctrip/extraction/cktepoch=1.ckpt \\ --paradigm extraction \\ --n_gpu '0' \\ --do_direct_eval \\ --eval_batch_size 128 \\ 结果本地测试 我们可以直接用这个产生的模型文件进行本地推理。注意这里的模型文件地址的指定为你刚刚训练产生的。\npython main.py --task tasd-cn \\ --dataset ctrip \\ --ckpoint_path outputs/tasd-cn/ctrip/extraction/cktepoch=1.ckpt \\ --text 早餐一般般，勉勉强强填饱肚子，样式可选性不多，可能是疫情的影响吧。不过酒店的服务不错，五个小孩早餐都送了，点👍。由于酒店历史有点长，所以设施感觉一般般，整体还可以，三钻吧 \\ --paradigm extraction \\ --n_gpu 0 \\ --do_direct_predict \\ 输出如下\nsents: 早餐一般般，勉勉强强填饱肚子，样式可选性不多，可能是疫情的影响吧。不过酒店的服务不错，五个小孩早餐都送了，点👍。由于酒店历史有点长，所以设施感觉一般般，整体还可以，三钻吧 pred: 0.5794262886047363 由于样本数据中空输出较多，且仅训练了一个epoch故模型倾向于输出空\n到这里，就完成了一个模型的训练过程。\n"},{"uri":"/02extraction/02train.html","title":"抽取式ABSA模型训练2","tags":[],"description":"","content":"paper - Utilizing BERT for Aspect-Based Sentiment Analysis via Constructing Auxiliary Sentence\u0026quot; (NAACL 2019)。 这个方法的输入输出设计很符合TABSA任务，做法简单，适合作为此类任务的baseline.\n我们现在会用sagemaker进行一个模型的本地训练，使用ml.p3.8xlarge机型。\n数据准备 首先下载代码\nsource activate pytorch_p37 cd SageMaker git clone https://github.com/jackie930/ABSA-BERT-pair.git 将数据data1119.csv上传到data/custom/data1119.csv\n模型训练 接下来我们运行训练，首先下载预训练模型并转换为torch版本\ncd ABSA-BERT-pair wget -P ./source/bert/pretrain_model/cn https://storage.googleapis.com/bert_models/2018_11_03/chinese_L-12_H-768_A-12.zip cd ./source/bert/pretrain_model/cn unzip chinese_L-12_H-768_A-12.zip pip install tensorflow==1.13.1 cd /home/ec2-user/SageMaker/ABSA-BERT-pair/ python convert_tf_checkpoint_to_pytorch.py \\ --tf_checkpoint_path ./source/bert/pretrain_model/cn/chinese_L-12_H-768_A-12/bert_model.ckpt \\ --bert_config_file ./source/bert/pretrain_model/cn/chinese_L-12_H-768_A-12/bert_config.json \\ --pytorch_dump_path ./source/bert/pretrain_model/cn/pytorch_model.bin 数据准备\ncd generate/ python generate_custom_NLI_M.py 然后进行模型训练，演示目的，只训练一个epoch\ncd ../ CUDA_VISIBLE_DEVICES=0,1,2,3 python run_classifier_TABSA-v1.py \\ --task_name custom_NLI_M \\ --data_dir data/custom/bert-pair/ \\ --vocab_file ./source/bert/pretrain_model/cn/chinese_L-12_H-768_A-12/vocab.txt \\ --bert_config_file ./source/bert/pretrain_model/cn/chinese_L-12_H-768_A-12/bert_config.json \\ --init_checkpoint ./source/bert/pretrain_model/cn/pytorch_model.bin \\ --eval_test \\ --do_lower_case \\ --max_seq_length 512 \\ --train_batch_size 48 \\ --learning_rate 2e-5 \\ --num_train_epochs 1.0 \\ --do_save_model \\ --output_dir results/custom/NLI_M \\ --seed 42 训练完成后，模型评估\npython evaluation.py --task_name custom_NLI_M --pred_data_dir results/custom/NLI_M/test_ep_1.txt "},{"uri":"/03generative.html","title":"动手实验2: 基于Amazon SageMaker训练一个端到端生成式的ABSA模型以及部署","tags":[],"description":"","content":"Generation-ABSA paper - Towards Generative Aspect-Based Sentiment Analysis (ACL 2021)\n模型架构 将完整的ABSA任务重新定义为序列生成任务，并给出两种训练模式 分解ABSA任务为Aspect Opinion Pair Extraction (AOPE)、UnifiedABSA (UABSA), spect Sentiment Triplet Extrac-tion (ASTE), Target Aspect Sentiment Detec-tion (TASD) 任务处理，所有子任务均用同样的训练模式训练\n模型表现 "},{"uri":"/03generative/0503deploy.html","title":"生成式ABSA模型部署","tags":[],"description":"","content":"首先打包镜像并推送\ncd endpoint sh build_and_push.sh generative-absa 然后部署一个预置的endpoint\n#注意修改：847380964353.dkr.ecr.ap-northeast-1.amazonaws.com/generative-absa为自己对应的 !python create_endpoint.py \\ --endpoint_ecr_image_path \u0026#34;847380964353.dkr.ecr.ap-northeast-1.amazonaws.com/generative-absa\u0026#34; \\ --endpoint_name \u0026#39;generative-absa\u0026#39; \\ --instance_type \u0026#34;ml.p3.2xlarge\u0026#34; 输出\nmodel_name: generative-absa endpoint_ecr_image_path: 847380964353.dkr.ecr.ap-northeast-1.amazonaws.com/generative-absa \u0026lt;\u0026lt;\u0026lt; Completed model endpoint deployment. generative-absa 当状态变为InService即代表部署完成\n在部署结束后，看到SageMaker控制台生成了对应的endpoint,可以使用如下客户端代码测试调用\n%%time from boto3.session import Session import json data={\u0026#34;data\u0026#34;: \u0026#39;早餐一般般，勉勉强强填饱肚子，样式可选性不多，可能是疫情的影响吧。不过酒店的服务不错，五个小孩早餐都送了，点👍。由于酒店历史有点长，所以设施感觉一般般，整体还可以，三钻吧\u0026#39;} session = Session() runtime = session.client(\u0026#34;runtime.sagemaker\u0026#34;) response = runtime.invoke_endpoint( EndpointName=\u0026#39;absa\u0026#39;, ContentType=\u0026#34;application/json\u0026#34;, Body=json.dumps(data), ) result = json.loads(response[\u0026#34;Body\u0026#34;].read()) print (result) 结果如下\n{'result': '(小孩早餐, 儿童餐饮, 送了点👍, 正)', 'infer_time': '0:00:00.725859'} "},{"uri":"/categories.html","title":"Categories","tags":[],"description":"","content":""},{"uri":"/tags.html","title":"Tags","tags":[],"description":"","content":""}]